{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import numpy as np\n",
    "import polars as pl\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.svm import SVC\n",
    "from toolz import keymap, merge\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import (\n",
    "    StratifiedKFold,\n",
    "    cross_validate,\n",
    "    GridSearchCV,\n",
    "    RepeatedStratifiedKFold,\n",
    "    cross_val_predict,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"svc\": SVC(probability=True, class_weight=\"balanced\"),\n",
    "    \"knn\": KNeighborsClassifier(n_jobs=1),\n",
    "    \"rf\": RandomForestClassifier(class_weight=\"balanced\", n_jobs=1),\n",
    "    \"gnb\": GaussianNB(),\n",
    "    \"lr\": LogisticRegression(\n",
    "        class_weight=\"balanced\", solver=\"saga\", n_jobs=1, max_iter=5_000, tol=1e-1,\n",
    "    ),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create sampling function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample items so that items in each category are reasonably distant from each other\n",
    "# - adds robustness to the model\n",
    "def get_sample(df: pl.DataFrame, n=100, random_state=0) -> pl.DataFrame:\n",
    "    \"\"\"Run k-Center algorithm to select most diverse samples for a category.\"\"\"\n",
    "    if len(df) <= n:\n",
    "        return df\n",
    "    distance_mtx = pdist(df[\"snowflake_embedding_clean\"].to_numpy(), metric=\"cosine\")\n",
    "    distance_mtx = squareform(distance_mtx)\n",
    "\n",
    "    rng = np.random.default_rng(random_state)\n",
    "\n",
    "    sample = rng.integers(0, len(df), size=1).tolist()\n",
    "    dist_row = distance_mtx[sample[0]]\n",
    "\n",
    "    for i in range(n - 1):\n",
    "        # make a bit robust, use quantile\n",
    "        idxes = np.argsort(dist_row)\n",
    "        pos = int(len(idxes) * 0.95)\n",
    "        idx = idxes[pos]\n",
    "        while idx in sample and pos < len(df):\n",
    "            pos += 1\n",
    "            idx = idxes[pos]\n",
    "\n",
    "        while idx in sample and pos >= 0:\n",
    "            pos -= 1\n",
    "            idx = idxes[pos]\n",
    "\n",
    "        sample.append(idx)\n",
    "        dist_row = np.minimum(dist_row, distance_mtx[sample[-1]])\n",
    "    \n",
    "    return df[sample]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data, create training dataset\n",
    "\n",
    "Run this cell and parameter scan cell for each LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_name = \"tulu\"\n",
    "\n",
    "if llm_name == \"granite\":\n",
    "    # granite\n",
    "    df = pl.scan_parquet(\n",
    "        \"../structured_output_v5/granite3_1-dense-8b_structured_output_df.parquet\"\n",
    "    )\n",
    "elif llm_name == \"tulu\":\n",
    "    # tulu\n",
    "    df = pl.scan_parquet(\"../structured_output_v5/tulu3_structured_output_df.parquet\")\n",
    "else:\n",
    "    raise ValueError(\"llm_name not recognized\")\n",
    "\n",
    "# merge with embedding df\n",
    "df = df.join(\n",
    "    pl.scan_parquet(\"../emails_with_tokens_and_embeddings_v5.parquet\").select(\n",
    "        [\n",
    "            \"subject\",\n",
    "            \"from\",\n",
    "            \"body\",\n",
    "            \"date\",\n",
    "            \"snowflake_embedding_clean\",\n",
    "            \"gte_embedding_clean\",\n",
    "        ]\n",
    "    ),\n",
    "    on=[\"subject\", \"from\", \"body\", \"date\"],\n",
    "    how=\"left\",\n",
    ").collect()\n",
    "\n",
    "df = df.drop_nulls(subset=[\"snowflake_embedding_clean\", \"gte_embedding_clean\"])\n",
    "df = df.filter(pl.col(\"snowflake_embedding_clean\").arr.sum() != 0).filter(\n",
    "    pl.col(\"primary_category\") != \"N/A\"  # came from CUDA error\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['primary_category'].value_counts(sort=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create class-balanced training dataset\n",
    "sample = pl.concat(\n",
    "    [\n",
    "        get_sample(_df, n=400, random_state=0)\n",
    "        for _df in df.partition_by(\"primary_category\", maintain_order=True)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run parameter scans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_params = {\n",
    "    \"n_components\": [25, 50, 250, 400],\n",
    "}\n",
    "\n",
    "svc_params = {\n",
    "    \"kernel\": [\"linear\", \"rbf\"],\n",
    "    \"C\": [1e-2, 0.1, 0.9],\n",
    "}\n",
    "\n",
    "knn_params = {\n",
    "    \"n_neighbors\": [5, 15, 50, 100],\n",
    "    \"weights\": [\"distance\"],\n",
    "    \"metric\": [\"euclidean\", \"cosine\", \"manhattan\"],\n",
    "}\n",
    "\n",
    "rf_params = {\n",
    "    \"n_estimators\": [50, 100, 150],\n",
    "    \"max_depth\": [5, 20, None],\n",
    "}\n",
    "\n",
    "gb_params = {\n",
    "    \"n_estimators\": [50, 100, 500],\n",
    "    \"max_depth\": [5, 20, None],\n",
    "}\n",
    "\n",
    "lr_params = {\n",
    "    \"C\": [0.001, 0.1, 1, 10, 100],\n",
    "    \"penalty\": [\"l1\", \"l2\"],\n",
    "}\n",
    "\n",
    "model_params = {\n",
    "    \"svc\": svc_params,\n",
    "    \"knn\": knn_params,\n",
    "    \"rf\": rf_params,\n",
    "    \"gb\": gb_params,\n",
    "    \"lr\": lr_params,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "for embedding_name in tqdm([\"gte_embedding_clean\", \"snowflake_embedding_clean\"]):\n",
    "    for model_name, model in tqdm(models.items()):\n",
    "        print(f\"Running {model_name} with {embedding_name}\")\n",
    "        pipeline = Pipeline(\n",
    "            [(\"pca\", PCA()), (\"scaler\", StandardScaler()), (\"model\", model)]\n",
    "        )\n",
    "        _model_params = model_params.get(model_name, {})\n",
    "        _model_params = keymap(lambda k: f\"model__{k}\", _model_params)\n",
    "        _model_params = {**_model_params, **keymap(lambda k: f\"pca__{k}\", pca_params)}\n",
    "\n",
    "        embedding = sample[embedding_name].to_numpy()\n",
    "        labels = sample[\"primary_category\"].to_numpy()\n",
    "\n",
    "        grid_search = GridSearchCV(\n",
    "            pipeline,\n",
    "            _model_params,\n",
    "            cv=StratifiedKFold(n_splits=4, shuffle=True, random_state=0),\n",
    "            n_jobs=5,\n",
    "            verbose=1,\n",
    "            scoring=\"f1_weighted\",\n",
    "\n",
    "        )\n",
    "        grid_search.fit(embedding, labels)\n",
    "        results[(embedding_name, model_name)] = pl.DataFrame(\n",
    "            grid_search.cv_results_, strict=False\n",
    "        ).sort(\"rank_test_score\")\n",
    "        print(results[(embedding_name, model_name)]['mean_test_score'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with warnings.catch_warnings(action=\"ignore\"):\n",
    "    combined_results = []\n",
    "    for k, v in results.items():\n",
    "        _df = (\n",
    "            v.select([\"mean_test_score\", \"params\"])\n",
    "            .head(10)\n",
    "            .with_columns(\n",
    "                pl.col(\"params\").map_elements(str, return_dtype=pl.String),\n",
    "                embedding=pl.lit(k[0]),\n",
    "                model=pl.lit(k[1]),\n",
    "            )\n",
    "        )\n",
    "        combined_results.append(_df)\n",
    "    combined_results = pl.concat(combined_results).sort(\n",
    "        \"mean_test_score\", descending=True\n",
    "    )\n",
    "combined_results.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_results.write_parquet(f\"../{llm_name}_model_selection_results.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot parameter scan results within LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = eval(combined_results[\"params\"][0])\n",
    "pipe = Pipeline(\n",
    "    [(\"pca\", PCA()), (\"scaler\", StandardScaler()), (\"model\", models[\"svc\"])]\n",
    ")\n",
    "pipe = pipe.set_params(**best_params)\n",
    "\n",
    "x = cross_validate(\n",
    "    pipe,\n",
    "    sample[\"snowflake_embedding_clean\"].to_numpy(),\n",
    "    sample[\"primary_category\"].to_numpy(),\n",
    "    cv=RepeatedStratifiedKFold(n_splits=4, n_repeats=10, random_state=0),\n",
    "    n_jobs=5,\n",
    "    scoring=[\"f1_weighted\", \"accuracy\"],\n",
    ")\n",
    "\n",
    "y = cross_validate(\n",
    "    pipe,\n",
    "    sample[\"gte_embedding_clean\"].to_numpy(),\n",
    "    sample[\"primary_category\"].to_numpy(),\n",
    "    cv=RepeatedStratifiedKFold(n_splits=4, n_repeats=10, random_state=0),\n",
    "    n_jobs=5,\n",
    "    scoring=[\"f1_weighted\", \"accuracy\"],\n",
    ")\n",
    "\n",
    "plt_df = pl.DataFrame({\"mdl\": \"snowflake\", \"f1\": x[\"test_f1_weighted\"]})\n",
    "plt_df = pl.concat([plt_df, pl.DataFrame({\"mdl\": \"gte\", \"f1\": y[\"test_f1_weighted\"]})])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.swarmplot(data=plt_df, x=\"mdl\", y=\"f1\", hue=\"mdl\", zorder=1)\n",
    "ax = sns.pointplot(\n",
    "    data=plt_df,\n",
    "    x=\"mdl\",\n",
    "    y=\"f1\",\n",
    "    color=\"k\",\n",
    "    ax=ax,\n",
    "    linestyle=\"none\",\n",
    "    zorder=2,\n",
    "    errorbar=(\"se\", 2),\n",
    ")\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snow = combined_results.filter(pl.col(\"embedding\") == \"snowflake_embedding_clean\").sort(\n",
    "    \"mean_test_score\", descending=True\n",
    ")\n",
    "gte = combined_results.filter(pl.col(\"embedding\") == \"gte_embedding_clean\").sort(\n",
    "    \"mean_test_score\", descending=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    plt.plot(\n",
    "        [0, 1],\n",
    "        [snow[\"mean_test_score\"][i], gte[\"mean_test_score\"][i]],\n",
    "        marker=\"o\",\n",
    "        color=\"k\",\n",
    "    )\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = sample[\"primary_category\"].to_numpy()\n",
    "y_pred = cross_val_predict(\n",
    "    pipe,\n",
    "    sample[\"snowflake_embedding_clean\"].to_numpy(),\n",
    "    y_true,\n",
    "    cv=StratifiedKFold(n_splits=4, shuffle=True, random_state=0),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot confusion matrix\n",
    "labels = sample[\"primary_category\"].unique().to_list()\n",
    "cm = confusion_matrix(y_true, y_pred, labels=labels)\n",
    "cm = cm / cm.sum(axis=1, keepdims=True) * 100\n",
    "\n",
    "cm_df = pl.DataFrame(cm, schema=labels).to_pandas()\n",
    "cm_df.index = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(\n",
    "    cm_df,\n",
    "    annot=True,\n",
    "    fmt=\"0.0f\",\n",
    "    cmap=\"mako\",\n",
    "    vmax=50,\n",
    "    cbar_kws={\"label\": \"Percent (%)\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare tulu with granite\n",
    "\n",
    "top_5_tulu = pl.read_parquet(\"../tulu_model_selection_results.parquet\").head(10)\n",
    "top_5_granite = pl.read_parquet(\"../granite_model_selection_results.parquet\").head(10)\n",
    "to_plt = pl.concat(\n",
    "    [\n",
    "        top_5_tulu.with_columns(llm=pl.lit(\"tulu\")),\n",
    "        top_5_granite.with_columns(llm=pl.lit(\"granite\")),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.swarmplot(data=to_plt, x=\"llm\", y=\"mean_test_score\", hue='model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    plt.plot(\n",
    "        [0, 1],\n",
    "        [top_5_tulu[\"mean_test_score\"][i], top_5_granite[\"mean_test_score\"][i]],\n",
    "        marker=\"o\",\n",
    "        color=\"k\",\n",
    "    )\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train classifiers for the top parameter set for each classifier type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(llm_name):\n",
    "    if llm_name not in (\"tulu\", \"granite\"): raise ValueError(\"llm_name not recognized\")\n",
    "\n",
    "    llm_prefix = \"tulu3\" if llm_name == \"tulu\" else \"granite3_1-dense-8b\"\n",
    "    df = pl.scan_parquet(f\"../structured_output_v5/{llm_prefix}_structured_output_df.parquet\")\n",
    "\n",
    "    # merge with embedding df\n",
    "    df = df.join(\n",
    "        pl.scan_parquet(\"../emails_with_tokens_and_embeddings_v5.parquet\").select(\n",
    "            [\n",
    "                \"subject\",\n",
    "                \"from\",\n",
    "                \"body\",\n",
    "                \"date\",\n",
    "                \"snowflake_embedding_clean\",\n",
    "                \"gte_embedding_clean\",\n",
    "            ]\n",
    "        ),\n",
    "        on=[\"subject\", \"from\", \"body\", \"date\"],\n",
    "        how=\"left\",\n",
    "    ).collect()\n",
    "\n",
    "    df = df.drop_nulls(subset=[\"snowflake_embedding_clean\", \"gte_embedding_clean\"])\n",
    "    df = df.filter(pl.col(\"snowflake_embedding_clean\").arr.sum() != 0).filter(\n",
    "        pl.col(\"primary_category\") != \"N/A\"  # came from CUDA error\n",
    "    )\n",
    "\n",
    "    # create class-balanced training dataset\n",
    "    sample = pl.concat(\n",
    "        [\n",
    "            get_sample(_df, n=400, random_state=0)\n",
    "            for _df in df.partition_by(\"primary_category\", maintain_order=True)\n",
    "        ]\n",
    "    )\n",
    "    return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_map = {\n",
    "    \"granite\": load_dataset(\"granite\"),\n",
    "    \"tulu\": load_dataset(\"tulu\")\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_results = (\n",
    "    pl.concat(\n",
    "        pl.read_parquet(f\"../{llm}_model_selection_results.parquet\").with_columns(\n",
    "            llm=pl.lit(llm)\n",
    "        )\n",
    "        for llm in [\"tulu\", \"granite\"]\n",
    "    )\n",
    "    .group_by([\"model\", \"llm\"])\n",
    "    .agg(\n",
    "        pl.struct([\"mean_test_score\", \"params\", \"embedding\"])\n",
    "        .sort_by(\"mean_test_score\", descending=True)\n",
    "        .first()\n",
    "    )\n",
    "    .unnest(\"mean_test_score\")\n",
    "    .sort(\"mean_test_score\", descending=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = []\n",
    "for result in top_results.iter_rows(named=True):\n",
    "    _sample = sample_map[result['llm']]\n",
    "    # if result['model'] == 'lr':  # ignore for now, takes too long\n",
    "        # continue\n",
    "    print(result)\n",
    "    best_params = eval(result['params'])\n",
    "    pipe = Pipeline(\n",
    "        [(\"pca\", PCA()), (\"scaler\", StandardScaler()), (\"model\", models[result['model']])]\n",
    "    )\n",
    "    pipe = pipe.set_params(**best_params)\n",
    "    x = cross_validate(\n",
    "        pipe,\n",
    "        _sample[result[\"embedding\"]].to_numpy(),\n",
    "        _sample[\"primary_category\"].to_numpy(),\n",
    "        cv=RepeatedStratifiedKFold(n_splits=4, n_repeats=10, random_state=0),\n",
    "        n_jobs=6,\n",
    "        scoring=[\"f1_weighted\", \"accuracy\"],\n",
    "    )\n",
    "    for i, (f1, acc) in enumerate(zip(x['test_f1_weighted'], x['test_accuracy'])):\n",
    "        result = merge(result, dict(f1=f1, acc=acc, iteration=i))\n",
    "        output.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = pl.DataFrame(output)\n",
    "output.write_parquet(\"../top_classifier_runs_per_type.parquet\", compression_level=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try making a stacking or bagging classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier, StackingClassifier, VotingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline(\n",
    "    [(\"pca\", PCA()), (\"scaler\", StandardScaler()), (\"model\", models['svc'])]\n",
    ").set_params(**eval(top_results['params'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag = BaggingClassifier(\n",
    "    estimator=pipe,\n",
    "    n_estimators=10,\n",
    "    bootstrap_features=True,\n",
    "    n_jobs=-1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xval = cross_validate(\n",
    "    bag,\n",
    "    sample_map[\"granite\"][\"snowflake_embedding_clean\"].to_numpy(),\n",
    "    sample_map[\"granite\"][\"primary_category\"].to_numpy(),\n",
    "    cv=StratifiedKFold(n_splits=4, shuffle=True, random_state=0),\n",
    "    n_jobs=1,\n",
    "    scoring=[\"f1_weighted\", \"accuracy\"],\n",
    ")\n",
    "xval['test_f1_weighted'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_map = {\n",
    "    'svc': 0,\n",
    "    'knn': 3,\n",
    "    'lr': 2\n",
    "}\n",
    "\n",
    "models_list = []\n",
    "\n",
    "for k, v in idx_map.items():\n",
    "    pipe = Pipeline(\n",
    "        [(\"pca\", PCA()), (\"scaler\", StandardScaler()), (\"model\", models[k])]\n",
    "    ).set_params(**eval(top_results['params'][v]))\n",
    "    models_list.append((k, pipe['model']))\n",
    "\n",
    "stack = StackingClassifier(estimators=models_list)\n",
    "\n",
    "pipe = Pipeline(\n",
    "    [(\"pca\", PCA()), (\"scaler\", StandardScaler()), (\"model\", stack)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xval = cross_validate(\n",
    "    pipe,\n",
    "    sample_map[\"granite\"][\"snowflake_embedding_clean\"].to_numpy(),\n",
    "    sample_map[\"granite\"][\"primary_category\"].to_numpy(),\n",
    "    cv=StratifiedKFold(n_splits=4, shuffle=True, random_state=0),\n",
    "    n_jobs=4,\n",
    "    scoring=[\"f1_weighted\", \"accuracy\"],\n",
    ")\n",
    "xval['test_f1_weighted'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_map = {\n",
    "    'svc': 0,\n",
    "    'knn': 3,\n",
    "    'lr': 2\n",
    "}\n",
    "\n",
    "models_list = []\n",
    "\n",
    "for k, v in idx_map.items():\n",
    "    pipe = Pipeline(\n",
    "        [(\"pca\", PCA()), (\"scaler\", StandardScaler()), (\"model\", models[k])]\n",
    "    ).set_params(**eval(top_results['params'][v]))\n",
    "    models_list.append((k, pipe['model']))\n",
    "\n",
    "voter = VotingClassifier(estimators=models_list, voting='soft')\n",
    "\n",
    "pipe = Pipeline(\n",
    "    [(\"pca\", PCA()), (\"scaler\", StandardScaler()), (\"model\", voter)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xval = cross_validate(\n",
    "    pipe,\n",
    "    sample_map[\"granite\"][\"snowflake_embedding_clean\"].to_numpy(),\n",
    "    sample_map[\"granite\"][\"primary_category\"].to_numpy(),\n",
    "    cv=StratifiedKFold(n_splits=4, shuffle=True, random_state=0),\n",
    "    n_jobs=4,\n",
    "    scoring=[\"f1_weighted\", \"accuracy\"],\n",
    ")\n",
    "xval['test_f1_weighted'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = top_results.to_dicts()[0]\n",
    "assert result['model'] == 'svc'\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline(\n",
    "    [(\"pca\", PCA()), (\"scaler\", StandardScaler()), (\"model\", models[result['model']])]\n",
    ").set_params(**eval(result['params']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = []\n",
    "_sample = sample_map[\"granite\"]\n",
    "for embedding in [\"snowflake_embedding_clean\", \"gte_embedding_clean\"]:\n",
    "    x = cross_validate(\n",
    "        pipe,\n",
    "        _sample[embedding].to_numpy(),\n",
    "        _sample[\"primary_category\"].to_numpy(),\n",
    "        cv=RepeatedStratifiedKFold(n_splits=4, n_repeats=10, random_state=0),\n",
    "        n_jobs=6,\n",
    "        scoring=[\"f1_weighted\", \"accuracy\"],\n",
    "    )\n",
    "    for i, (f1, acc) in enumerate(zip(x['test_f1_weighted'], x['test_accuracy'])):\n",
    "        result = merge(result, dict(f1=f1, acc=acc, iteration=i, embedding=embedding))\n",
    "        output.append(result)\n",
    "output = pl.DataFrame(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.write_parquet(\"../compare_embeddings_for_classification.parquet\", compression_level=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test on validation data (all other samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# granite\n",
    "df = pl.scan_parquet(\n",
    "    \"../structured_output_v5/granite3_1-dense-8b_structured_output_df.parquet\"\n",
    ")\n",
    "\n",
    "# merge with embedding df\n",
    "df = df.join(\n",
    "    pl.scan_parquet(\"../emails_with_tokens_and_embeddings_v5.parquet\").select(\n",
    "        [\n",
    "            \"subject\",\n",
    "            \"from\",\n",
    "            \"body\",\n",
    "            \"date\",\n",
    "            \"snowflake_embedding_clean\",\n",
    "        ]\n",
    "    ),\n",
    "    on=[\"subject\", \"from\", \"body\", \"date\"],\n",
    "    how=\"left\",\n",
    ").collect()\n",
    "\n",
    "df = df.drop_nulls(subset=[\"snowflake_embedding_clean\"])\n",
    "df = df.filter(pl.col(\"snowflake_embedding_clean\").arr.sum() != 0).filter(\n",
    "    pl.col(\"primary_category\") != \"N/A\"  # came from CUDA error\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = top_results.to_dicts()[0]\n",
    "assert result['model'] == 'svc'\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline(\n",
    "    [(\"pca\", PCA()), (\"scaler\", StandardScaler()), (\"model\", models[result['model']])]\n",
    ").set_params(**eval(result['params']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_sample = sample_map[\"granite\"]\n",
    "pipe = pipe.fit(\n",
    "    _sample[\"snowflake_embedding_clean\"].to_numpy(),\n",
    "    _sample[\"primary_category\"].to_numpy(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove entries from _sample\n",
    "smaller_df = df.join(_sample.select([\"subject\", \"from\", \"body\", \"date\"]), how=\"anti\", on=[\"subject\", \"from\", \"body\", \"date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import balanced_accuracy_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = pipe.predict(smaller_df[\"snowflake_embedding_clean\"].to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_accuracy_score(smaller_df[\"primary_category\"].to_numpy(), preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score(smaller_df[\"primary_category\"].to_numpy(), preds, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_probs = pipe.predict_log_proba(smaller_df[\"snowflake_embedding_clean\"].to_numpy()[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy(log_probs):\n",
    "    return -np.sum(np.exp(log_probs) * log_probs, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entropies = entropy(log_probs)\n",
    "sorted_inds = np.argsort(entropies)\n",
    "plt.plot(np.sort(entropy(log_probs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entropies[sorted_inds[700]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.quantile(entropies, 0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entropies[sorted_inds[950]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.exp(log_probs[[2, 31]]).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rich.table import Table\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "\n",
    "def print_email(idx):\n",
    "    for col in [\"from\", \"subject\", \"body\"]:\n",
    "        if col == \"body\":\n",
    "            display(HTML(smaller_df[col][idx]))\n",
    "        else:\n",
    "            print(smaller_df[col][idx])\n",
    "\n",
    "\n",
    "def create_confidence_output(log_probs, model, n_show=4):\n",
    "    table = Table(show_header=True, header_style=\"bold magenta\")\n",
    "    table.add_column(\"Confidence\", justify=\"right\")\n",
    "    table.add_column(\"Category\", justify=\"left\")\n",
    "    sorted_idx = np.argsort(log_probs)[::-1][:n_show]\n",
    "    probs = np.exp(log_probs[sorted_idx])[:n_show] * 100\n",
    "    rep = [f\"{pct:0.0f}%: {model.classes_[idx]}\" for idx, pct in zip(sorted_idx, probs)]\n",
    "    for pct, cat in zip(probs, model.classes_[sorted_idx]):\n",
    "        table.add_row(f\"{pct:0.0f}%\", cat)\n",
    "    return table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(15):\n",
    "    idx = int(sorted_inds[i])\n",
    "    print_email(idx)\n",
    "    display(create_confidence_output(log_probs[idx], pipe))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, 16):\n",
    "    idx = int(sorted_inds[-i])\n",
    "    print_email(idx)\n",
    "    display(create_confidence_output(log_probs[idx], pipe))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = int(sorted_inds[940])\n",
    "\n",
    "print(\"entropy:\", entropies[idx])\n",
    "print_email(idx)\n",
    "display(create_confidence_output(log_probs[idx], pipe))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "email",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
